{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates timecourse analyses and figures for experiments 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import seaborn as sb; import warnings; import scipy; import re; \n",
    "import os; from analysis_helpers import *; import itertools; from scipy import stats\n",
    "import random; import pandas as pd; import numpy as np; from sklearn import datasets, linear_model; \n",
    "from sklearn.linear_model import LinearRegression; import statsmodels.api as sm\n",
    "from scipy import stats; from itertools import groupby; from operator import itemgetter; import pingouin\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Behavioral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../parsed_data/FULL_DATA.csv')\n",
    "data = pd.read_csv('../parsed_data/full_behavioral.csv')\n",
    "\n",
    "data['Uncued Face'] = data['Uncued Composite'].str.split('_', n=1, expand=True)[0]+'.jpg'\n",
    "data['Uncued Place'] = data['Uncued Composite'].str.split('_', n=1, expand=True)[1]\n",
    "data['Cued Face'] = data['Cued Composite'].str.split('_', n=1, expand=True)[0]+'.jpg'\n",
    "data['Cued Place'] = data['Cued Composite'].str.split('_', n=1, expand=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participant with UniqueID 81 did not respond to the last six presentation trials in presentation Run 4 and may not have seen these images (see compile_data.ipynb). As such, the familiarity ratings for the images from these trials presented during the memory run are not included in the analyses. Here, we remove them before conducting our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cued_face_81_4    = list(data[(data['Attention Button']!=1.0)&(data['Attention Button']!=3.0)&(data['Trial Type']=='Presentation')]['Cued Face'])#['Attention Button']\n",
    "cued_place_81_4   = list(data[(data['Attention Button']!=1.0)&(data['Attention Button']!=3.0)&(data['Trial Type']=='Presentation')]['Cued Place'])#['Attention Button']\n",
    "uncued_face_81_4  = list(data[(data['Attention Button']!=1.0)&(data['Attention Button']!=3.0)&(data['Trial Type']=='Presentation')]['Uncued Face'])#['Attention Button']\n",
    "uncued_place_81_4 = list(data[(data['Attention Button']!=1.0)&(data['Attention Button']!=3.0)&(data['Trial Type']=='Presentation')]['Uncued Place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_images = cued_face_81_4 + cued_place_81_4 + uncued_face_81_4 + uncued_place_81_4\n",
    "run_4_mem = data[(data['UniqueID']==81) & (data['Trial Type']=='Memory')&(data['Run']==4)]\n",
    "\n",
    "drop_index = run_4_mem.loc[run_4_mem['Memory Image'].isin(missed_images)].index\n",
    "\n",
    "data = data.drop(drop_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Behavioral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Add cued category from last presentation trial to memory blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each memory trial, add which category was last cued before that memory trial began\n",
    "\n",
    "# for each participant\n",
    "for s in data['UniqueID'].unique():\n",
    "    \n",
    "    # for each run of that participant's data\n",
    "    for r in data['Run'].unique():\n",
    "        \n",
    "        # select the memory trials for that participant for that run\n",
    "        # set Last Cued for Memory trials of this run equal to:\n",
    "        # the Cued Category in the last presentation trial of the run (Trial #9) \n",
    "        data.loc[(data['Run']==r) \n",
    "                 & (data['UniqueID']==s) \n",
    "                 & (data['Trial Type']=='Memory'), 'Last Cued'] = data[(data['Run']==r) & (data['UniqueID']==s) & (data['Trial Type']=='Presentation') & (data['Trial']==9)]['Cued Category'].item()\n",
    "        \n",
    "# make a copy of the data where novel images labeled by whether they are in the last-cued image category\n",
    "\n",
    "# data_nov = copy of the original data where Novel images are not distinguished from each other\n",
    "data_nov = data\n",
    "\n",
    "# use the add_nov_labels function to label the Novel images Cued_Novel or Uncued_Novel\n",
    "# data = dataframe with labeled novel images\n",
    "data     = add_nov_label(data, column_name = 'Last Cued')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are all of the statistical tests done on the behavioral data, roughly in the order they appear in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory responses entered within 2.012 secs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['Familiarity Reaction Time (s)']>2.012), 'Familiarity Rating']=np.nan\n",
    "data.loc[(data['Familiarity Reaction Time (s)']>2.012), 'Familiarity Reaction Time (s)']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction Time Stats (Cued vs. Uncued side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare average attention probe reaction times (valid versus invalid)\n",
    "\n",
    "# group experiment data by UniqueID, Cue Validity, and Experiment\n",
    "data_gr = data.groupby(['UniqueID','Cue Validity', 'Experiment'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    # select data for that exp only\n",
    "    dat = data_gr[(data_gr['Experiment']== experiment)]\n",
    "\n",
    "    print('exp : '+ experiment)\n",
    "    \n",
    "    # conduct paired t-test on participants' average reaction times to valid versus invalid probes\n",
    "    print(scipy.stats.ttest_rel(dat[dat['Cue Validity']==1]['Attention Reaction Time (s)'], \n",
    "                                dat[dat['Cue Validity']==0]['Attention Reaction Time (s)']))\n",
    "    \n",
    "    print('cohen d, repeated measure: '+str(cohen_d(list(dat[dat['Cue Validity']==1]['Attention Reaction Time (s)']), \n",
    "                                list(dat[dat['Cue Validity']==0]['Attention Reaction Time (s)']), repeated=True)))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make empty dictionary, diffs\n",
    "diffs = {}\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    # make a key in the diffs dictionary for this experiment\n",
    "    diffs[experiment] = []\n",
    "    \n",
    "    # select the data for this experiment only\n",
    "    d = data_gr[(data_gr['Experiment']== experiment)]\n",
    "\n",
    "    # for each participant in the experiment\n",
    "    for s in d['Subject'].unique():\n",
    "        \n",
    "        # calculate participant's average reaction time to valid and invalid probes\n",
    "        cued   = d[(d['Subject']==s)&(d['Cue Validity']==0)]['Attention Reaction Time (s)'].mean()\n",
    "        uncued = d[(d['Subject']==s)&(d['Cue Validity']==1)]['Attention Reaction Time (s)'].mean()\n",
    "\n",
    "        # obtain the difference in their mean RT to cued versus uncued probes ( cued - uncued )\n",
    "        # append this difference value to this experiment's key in the diffs dictionary\n",
    "        diffs[experiment].append(cued - uncued)\n",
    "\n",
    "# conduct an independent t-test comparing RT differences in each experiment\n",
    "print('RT Diff Comparison')\n",
    "print(scipy.stats.ttest_ind(diffs['/sustain'], diffs['/variabl']))\n",
    "\n",
    "print(\"cohen's d: \" + str(cohen_d(diffs['/sustain'], diffs['/variabl'], repeated=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Fully Attended images to all other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare average ratings for fully attended images to all other image types \n",
    "\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "# for each experiment\n",
    "\n",
    "    # make empty lists Fulls and Others\n",
    "    Fulls  = []\n",
    "    Others = []\n",
    "\n",
    "    # for each participant in this experiment\n",
    "    for s in data[(data['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        # append participant's average Familiarity Rating for Fully attended images to Fulls list\n",
    "        Fulls.append(data[(data['UniqueID']==s)&(data['Attention Level']=='Full') & (data['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "        # append participant's average Familiarity Rating for all other images (Category, Side, None, Novel_Cued, Novel_Uncued) to Others\n",
    "        Others.append(data[(data['UniqueID']==s)&(data['Attention Level']!='Full') & (data['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "    # conduct paired t-test comparing Fully attended image ratings to ratings for all other images\n",
    "    print()\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(Fulls, Others))\n",
    "    print(\"cohen's: \"+str(cohen_d(Fulls, Others, repeated=True)))\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face versus Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ratings for fully attended scenes with ratings for fully attended faves\n",
    "\n",
    "# group data by participant, experiment, attn level, and image category (face or place)\n",
    "f_p = data.groupby(['UniqueID', 'Experiment', 'Attention Level', 'Category'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "        print()\n",
    "\n",
    "        print('experiment : '+experiment)\n",
    "\n",
    "        # conduct a paired t-test comparing Familiarity Ratings for Fully attended Place images and Fully attended Face images\n",
    "        print(scipy.stats.ttest_rel(f_p[(f_p['Category']=='Place') & (f_p['Attention Level']=='Full') \n",
    "                                        & (f_p['Experiment']==experiment)]['Familiarity Rating'], \n",
    "\n",
    "                                    f_p[(f_p['Category']=='Face') & (f_p['Attention Level']=='Full') \n",
    "                                        & (f_p['Experiment']==experiment)]['Familiarity Rating']))\n",
    "\n",
    "        print(\"cohen's: \"+str(cohen_d(list(f_p[(f_p['Category']=='Place') & (f_p['Attention Level']=='Full') \n",
    "                                & (f_p['Experiment']==experiment)]['Familiarity Rating']), \n",
    "\n",
    "                            list(f_p[(f_p['Category']=='Face') & (f_p['Attention Level']=='Full') \n",
    "                                & (f_p['Experiment']==experiment)]['Familiarity Rating']), repeated=True)))\n",
    "\n",
    "        print ()\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attended Category versus Unattended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group data by participant, experiment, and attn level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    # make empty lists Cats and Nones\n",
    "    Cats  = []\n",
    "    Nones = []\n",
    "\n",
    "    # for each participant in this experiment\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        # append participant's average Familiarity Rating for Category attended images to Cats list\n",
    "        Cats.append(d[(d['UniqueID']==s) & (d['Attention Level'].isin(['Category']) & (d['Experiment']==experiment))]['Familiarity Rating'].mean())\n",
    "        # append participant's average Familiarity Rating for None attended images to Nones list\n",
    "        Nones.append(d[(d['UniqueID']==s) & (d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "    # conduct a paired t-test comparing average rating of Category attention level images and None attention level images\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(Cats, Nones))\n",
    "    print(\"cohen's: \"+str(cohen_d(Cats, Nones, repeated=True)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attended Side vs Unattended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by UniqueID, Experiment, Attention Level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# for each experiment \n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    # make empty lists Sides and Nones    \n",
    "    Sides  = []\n",
    "    Nones = []\n",
    "    \n",
    "    # for each participant in the select experiment\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        # append participant's average Familiarity Rating for Side attended images to Sides list\n",
    "        Sides.append(d[(d['UniqueID']==s) & (d['Attention Level'].isin(['Side'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "        # append participant's average Familiarity Rating for None attended images to Nones list\n",
    "        Nones.append(d[(d['UniqueID']==s) & (d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean())\n",
    "\n",
    "    # conduct paired t-test between average ratings for Side attended and None attended images\n",
    "    print(scipy.stats.ttest_rel(Sides, Nones))\n",
    "    print(\"cohen's: \"+str(cohen_d(Sides, Nones, repeated=True)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cued versus Uncued Novel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by UniqueID, Experiment, Attention Level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "    \n",
    "    # obtain familiarity ratings for Nov_Cued and Nov_Un images\n",
    "    a = d[(d['Attention Level']=='Nov_Cued') & (d['Experiment']==experiment)]['Familiarity Rating']\n",
    "    b = d[(d['Attention Level']=='Nov_Un') & (d['Experiment']==experiment)]['Familiarity Rating']\n",
    "\n",
    "    # conduct a paired t-test comparing average ratings for Nov_Cued and Nov_Un images\n",
    "    print(experiment)\n",
    "    print(scipy.stats.ttest_rel(a, b))\n",
    "    print(\"cohen's: \"+str(cohen_d(list(a), list(b), repeated=True)))\n",
    "\n",
    "    # print(cohen_d(a, b))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature boost versus feature bias boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group data by participant, experiment, attention level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    # make empty lists cat_no and nov_diff\n",
    "    cat_no   = []\n",
    "    nov_diff = []\n",
    "\n",
    "    # for each participant in the select experiment\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "        \n",
    "        # obtain average familiarity rating for images in the cued category (Category attended or Full attended)\n",
    "        cat = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Category', 'Full']))& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average familiarity rating for None attended images\n",
    "        no = d[(d['UniqueID']==s) &(d['Attention Level']=='None')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average familiarity ratings for novel images in the cued category \n",
    "        nov_c = d[(d['UniqueID']==s) &(d['Attention Level']=='Nov_Cued')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average familiarity ratings for novel images in the uncued category \n",
    "        nov_u = d[(d['UniqueID']==s) &(d['Attention Level']=='Nov_Un')& (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        # find the difference between cued-cat images (Full or Category) and None attended images\n",
    "        # append to cat_no list\n",
    "        cat_no.append(cat - no)\n",
    "        \n",
    "        # find the difference between cued novel and uncued novel images\n",
    "        # append to the nov_diff list\n",
    "        nov_diff.append(nov_c - nov_u)\n",
    "\n",
    "    # conduct a paired t-test\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_no, nov_diff))\n",
    "    print(cohen_d(cat_no, nov_diff, repeated=True))\n",
    "    #print(cohen_d(cat_no, nov_diff))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature boost versus Location boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOWN BELOW:\n",
    "\n",
    "# mean(Cat & Full) - mean(None)\n",
    "# versus\n",
    "# mean(Side & Full) - mean(None)\n",
    "\n",
    "# -------------------------------\n",
    "# NOT YET REPLICATED IN NEW DATA:\n",
    "\n",
    "# Experiment 1: ( (mean(Cat & Full) - mean(None))  -    (mean(Side & Full) - mean(None)) )    \n",
    "# versus\n",
    "# Experiment 2: ( (mean(Cat & Full) - mean(None))   -    (mean(Side & Full) - mean(None)) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by participant, experiment, attention level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# make empty dictionaries (full, diffs, and side_diffs)\n",
    "full = {}; diffs = {}; side_diffs = {}\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    # set label equal to experiment name\n",
    "    label = experiment \n",
    "\n",
    "    # make empty lists cat_nov and side_nov\n",
    "    cat_nov  = []\n",
    "    side_nov = []\n",
    "\n",
    "    # for each participant in this experiment\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "        \n",
    "        # obtain average ratings for images that were presented on the attended side (Side attended or Full attended)\n",
    "        side = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Side','Full'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average ratings for images that were in the attended caategory (Category attended or Full attended)\n",
    "        cat  = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Category', 'Full'])) & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average familiarity ratings for images that were None attended\n",
    "        nov  = d[(d['UniqueID']==s)&(d['Attention Level']=='None') & (d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        # obtain the difference between cat-attended and none-attended\n",
    "        cat_nov.append(cat - nov)\n",
    "        \n",
    "        # obtain the difference between side-attended and non-attended\n",
    "        side_nov.append(side - nov)\n",
    "\n",
    "    # conduct paired t-test comparing cat and none differences with side and none differences\n",
    "    print()\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_nov, side_nov))\n",
    "    print(cohen_d(cat_nov, side_nov, repeated=True))\n",
    "    print()\n",
    "    \n",
    "    # calculate the difference between cat_none differences and side_none differences \n",
    "    diff = [x-y for x,y in zip(cat_nov, side_nov)]\n",
    "    \n",
    "    # add the difference values between cat_none diffs and side_non diffs to diffs dictionary\n",
    "    # add to the key for this experiment\n",
    "    diffs[label] = diff\n",
    "    \n",
    "    # add the side_none differences to the side_diff dictionary in a key for this experiment\n",
    "    side_diffs[label] = side_nov\n",
    "    \n",
    "\n",
    "# conduct an independent t-test comparing cat_none and side_none differences from the two experiments\n",
    "print()\n",
    "print('Feature boost relative to Location boost, Exp1 vs Exp 2')\n",
    "print(scipy.stats.ttest_ind(diffs['/sustain'], diffs['/variabl']))\n",
    "print(cohen_d(diffs['/sustain'], diffs['/variabl']))\n",
    "#print(cohen_d(diffs['/sustain'], diffs['/variabl']))\n",
    "\n",
    "# conduct an independent t-test comparing side_none differences from the two experiments\n",
    "print()\n",
    "print('Location boost relative to none, Exp2 vs Exp1')\n",
    "print(scipy.stats.ttest_ind(side_diffs['/sustain'], side_diffs['/variabl']))\n",
    "print(cohen_d(side_diffs['/sustain'], side_diffs['/variabl']))\n",
    "# print(cohen_d(side_diffs['/sustain'], side_diffs['/variabl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Attended versus Side Attended boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by participant, experiment, attention level\n",
    "d = data.groupby(['UniqueID', 'Experiment', 'Attention Level'], as_index=False).mean()\n",
    "\n",
    "# make empty dictionary, full\n",
    "full = {}\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain', '/variabl']:\n",
    "        \n",
    "    # set label equal to experiment name\n",
    "    label = experiment \n",
    "\n",
    "    # make empty lists \n",
    "    cat_nov  = []\n",
    "    side_nov = []\n",
    "\n",
    "    # for each participant\n",
    "    for s in d[(d['Experiment']==experiment)]['UniqueID'].unique():\n",
    "\n",
    "        # obtain average rating for Side attended images\n",
    "        side = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Side']))&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average rating for Full attended images\n",
    "        cat  = d[(d['UniqueID']==s)&(d['Attention Level'].isin(['Full']))&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "        \n",
    "        # obtain average rating for None attended images\n",
    "        nov  = d[(d['UniqueID']==s)&(d['Attention Level']=='None')&(d['Experiment']==experiment)]['Familiarity Rating'].mean()\n",
    "\n",
    "        # obtain difference between average ratings for Full attended and None attended images\n",
    "        cat_nov.append(cat - nov)\n",
    "        \n",
    "        # obtain differece between average ratings for Side attended and None attended images\n",
    "        side_nov.append(side - nov)\n",
    "\n",
    "    # conduct paired t-test for cat-none differences and side-none differences\n",
    "    print('experiment : '+experiment)\n",
    "    print(scipy.stats.ttest_rel(cat_nov, side_nov))\n",
    "    print(cohen_d(cat_nov, side_nov, repeated=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_original.groupby(['Attention Level']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use lines on the violin plots to denote significance differences across violins and stars to indicate significant differences between the two categories within each violin. Note that in the case of variable attention experiment, some participants maay not have any cued novel or uncued novel images in a particular image category. In cases where this happens, we employ an unpaired t-test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data original is the data\n",
    "data_original = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT PARAMS\n",
    "snoop = 0\n",
    "stat_dict_full = {'/sustain':{}, '/variabl':{}}\n",
    "\n",
    "# color list \n",
    "col = ['r','orange','tan','purple','blue','grey']\n",
    "\n",
    "# cat list\n",
    "cats = ['Full','Category','Nov_Cued','Side','None','Nov_Un']\n",
    "\n",
    "# plot settings\n",
    "sb.set_style(\"white\")\n",
    "plt.grid(False)\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.xlabel('Attention Level',    fontsize = 20)\n",
    "plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "\n",
    "# for each experiment, for each test group, group and plot\n",
    "\n",
    "# for each experiment\n",
    "for experiment in ['/sustain','/variabl']:\n",
    "    \n",
    "    # set label equal to experiment\n",
    "    label = experiment \n",
    "\n",
    "    # select data for this experiment\n",
    "    d = data_original[(data_original['Experiment']==experiment)]\n",
    "\n",
    "\n",
    "    # VIOLIN PLOT\n",
    "    \n",
    "    # group data by participant, attention level, category (face or place)\n",
    "    data = d.groupby(['UniqueID','Attention Level', 'Category'], as_index = False).mean()\n",
    "    \n",
    "    print(label + ': Average Familiarity by Attention Level')\n",
    "    \n",
    "    # plot data: x-axis - attention level; y-axis - rating; hue - category (facae or place)\n",
    "    sb_plot = sb.violinplot(x='Attention Level', y='Familiarity Rating', \n",
    "                 data = data, split=True, hue='Category', \n",
    "                 order=cats)\n",
    "    \n",
    "    sb_plot.set(ylim=(.2, 9))\n",
    "    \n",
    "    ax1 = sb_plot.axes\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ### SIGNIFICANCE STARS FOR PLOTTING ###\n",
    "    \n",
    "    # make empty dictionary, t_draw\n",
    "    t_draw = {}\n",
    "    \n",
    "    # for each attention level\n",
    "    for c in data['Attention Level'].unique():\n",
    "        \n",
    "        # get the familiarity ratings for Face images at this attention level\n",
    "        first  = list(data[(data['Attention Level']==c) & (data['Category']=='Face')]['Familiarity Rating'])\n",
    "        \n",
    "        # get the familiarity ratings for Place images at this attention level\n",
    "        second = list(data[(data['Attention Level']==c) & (data['Category']=='Place')]['Familiarity Rating'])\n",
    "        \n",
    "        # we want to do a paired t-test between average ratings for Place and Face images attended at each level\n",
    "        # however, in the variable attention experiment, there may be participants who always had the same last-cued category\n",
    "        # (because category cues are given in a random order)\n",
    "        \n",
    "        if len(first) == len(second):\n",
    "\n",
    "            # conduct a paired t-test between familiarity ratings for Face and Place images attended at that level\n",
    "            t = scipy.stats.ttest_rel(first, second)\n",
    "            \n",
    "        elif len(first) != len(second):\n",
    "            \n",
    "            # conduct an independent t-test between familiarity ratings for Face and Place images attended at that level\n",
    "            t = scipy.stats.ttest_ind(first, second)\n",
    "            print(experiment)\n",
    "            print(c)\n",
    "\n",
    "        # apply symbol appropriate to the significance level\n",
    "        if t[1]<.001:\n",
    "            t_draw[c] = '***'\n",
    "        \n",
    "        elif t[1]<.01:\n",
    "            t_draw[c] = '**'\n",
    "\n",
    "        elif t[1]<.05:\n",
    "            t_draw[c] = '*'\n",
    "\n",
    "        elif t[1]<.0551:\n",
    "            t_draw[c] = '+'\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "    ### SIGNIFICANCE BETWEEN VIOLINS FOR PLOTTING ###\n",
    "    \n",
    "    # make empty dictionary for this experiment, stat_dict\n",
    "    stat_dict = {}\n",
    "    \n",
    "    # group data by participant, attention level\n",
    "    k = data.groupby(['UniqueID','Attention Level'],as_index=False).mean()\n",
    "\n",
    "    # use itertools to make a tuple for every possible attention level combination (Full & Side, None & Category, etc)\n",
    "    # for each tuple (eacah attention level pair)\n",
    "    for pair in list(itertools.combinations(cats, r=2)):\n",
    "        \n",
    "        # conduct a pairerd t-test between the ratings for that attention level\n",
    "        t = stats.ttest_rel(k[k['Attention Level']==pair[0]]['Familiarity Rating'], \n",
    "                            k[k['Attention Level']==pair[1]]['Familiarity Rating'])\n",
    "        \n",
    "        # add the t-stat and p-value from the test to the stat_dict_full dict for this experiment\n",
    "        # within this experiment dict, add it to the key for this specific attention level pair\n",
    "        stat_dict_full[label][pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "        \n",
    "        # if the p-value is less than chosen threshold, also add the t- and p-values to the stat_dict_pair dictionary\n",
    "        # use the key for this specific attention level pair\n",
    "        if t[1]<=.05:\n",
    "            stat_dict[pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "\n",
    "\n",
    "    ### CREATE AND ADD SIGNIFICANCE LINES TO PLOT ###\n",
    "    \n",
    "    # for each possible relationship (positive or negative difference in scores)\n",
    "    for relationship in  ['pos','neg']:\n",
    "    \n",
    "        # make empty lists, plotted_cats, to_be_plotted\n",
    "        plotted_cats = []\n",
    "        to_be_plotted = []\n",
    "        \n",
    "        # set line_height equal to zero\n",
    "        line_height = 0\n",
    "\n",
    "        # for each attention level\n",
    "        for idx,c in enumerate(cats):\n",
    "\n",
    "            x = sig_bars(c, cats, stat_dict, sign=relationship)\n",
    "            # obtain all significant 'relationship'-signed relationshps from this attn level \n",
    "            # to every other attn level, from nearest to farest cat on the plot\n",
    "\n",
    "            for idx,line in enumerate(x):\n",
    "            # for each line from this category to another category \n",
    "            # starting with the nearest category)\n",
    "\n",
    "                if (line['categories'] not in plotted_cats) and (line!=np.nan) and (type(line['categories'])!=float):\n",
    "                # if there is a difference in the correct direction (pos/neg) and it has not been plotted yet\n",
    "\n",
    "                    line['y'] = line['y'] + line_height\n",
    "                    # assign the next available height to this line \n",
    "                    # (give its height a boost based on how many lines have been plotted already)\n",
    "\n",
    "                    to_be_plotted.append(line)\n",
    "                    # append this line to the list of lines to be plotted\n",
    "\n",
    "                    plotted_cats.append(line['categories'])\n",
    "                    # add this category pair to the list of category pairs that has been plotted\n",
    "\n",
    "                    # CONTINUE THE CASCADE OF LINES\n",
    "                    # now, start from the category we have just drawn a line to\n",
    "                    # and loop through the rest of the categories from there\n",
    "\n",
    "                    # first, give the line a new name so we can loop over new lines, without losing our first one\n",
    "                    b = line\n",
    "\n",
    "                    # as long as there is difference in the correct direction (pos/neg) \n",
    "                    # between the most recent category and the next one\n",
    "                    while b['next']!= 0 :\n",
    "\n",
    "                        # grab the first category for the line between them\n",
    "                        first_cat = b['categories'][0]\n",
    "\n",
    "                        # then get the line STARTING from the category we have just drawn a line to, to the NEXT category it differs from\n",
    "                        b = sig_bars(b['next'], cats, stat_dict, sign=relationship)[0]\n",
    "\n",
    "                        # if there is a difference in the correct direction (pos/neg) that has not been plotted yet\n",
    "                        if (b['categories'] not in plotted_cats) and (b != np.nan) and (type(b['categories'])!=float):\n",
    "\n",
    "                            # adjust its height so it is the same height as the line that brought us here\n",
    "                            b['y'] = b['y'] + line_height\n",
    "\n",
    "                            # add this line to the lines we will plot\n",
    "                            to_be_plotted.append(b)\n",
    "\n",
    "                            # add this category pair to the list of pairs that's been plotted\n",
    "                            plotted_cats.append(b['categories'])\n",
    "\n",
    "                            # also add the pair of categories containing the original starting category and this ending category\n",
    "                            # (so that doesn't get plotted redundantly)\n",
    "                            plotted_cats.append((line['categories'][0], b['categories'][1]))\n",
    "\n",
    "                            # AND add the relationship from the original starting category to this starting category\n",
    "                            # (so that doesn't get plotted redundantly)\n",
    "                            plotted_cats.append((first_cat, b['categories'][1]))\n",
    "\n",
    "                    line_height = line_height - .4\n",
    "                    # adjust height next lines will be drawn at\n",
    "\n",
    "        # Plot the lines\n",
    "        for each in to_be_plotted:\n",
    "\n",
    "            if relationship == 'pos':\n",
    "                ax1.axhline(each['y'], ls='-', xmin = each['x_min'], xmax = each['x_max'], \n",
    "                    linewidth = each['width'], color = col[cats.index(each['categories'][0])])\n",
    "\n",
    "            if relationship == 'neg':\n",
    "                ax1.axhline(each['y']-2, ls='-', xmin = each['x_min'], xmax = each['x_max'], \n",
    "                    linewidth = each['width'], color = col[-cats.index(each['categories'][1])])\n",
    "\n",
    "    # Plot the stars\n",
    "    for stars in t_draw:\n",
    "        ax1.text((cats.index(stars)), 4.5, t_draw[stars], horizontalalignment='center', size='large', color='black')\n",
    "\n",
    "    # save figure\n",
    "    snoop +=1\n",
    "    stat_dict_full[label][pair] = {'t': t.statistic, 'p': t.pvalue}\n",
    "    if snoop ==2:\n",
    "        plt.savefig(\"violindoo.pdf\")\n",
    "\n",
    "    # show figure\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timecourse Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_window(combo, window_length):\n",
    "    '''\n",
    "    input:  dataframe of behavioral data from an entire experiment\n",
    "    output: dataframe of same shape where raw values have been replaced by rolling window mean\n",
    "    '''\n",
    "\n",
    "    # select data from memory runs\n",
    "    data = combo[combo['Trial Type']=='Memory'][['Attention Level','Familiarity Rating','Trial','UniqueID','Run']]\n",
    "\n",
    "    # re-structure the data - each row is a trial, each column is an attn level\n",
    "    df = data.pivot_table(index=['UniqueID', 'Trial'], columns='Attention Level', values='Familiarity Rating')\n",
    "\n",
    "    # apply rolling window, for each subject\n",
    "    window_data = df.groupby(['UniqueID']).apply(lambda x: x.rolling(window_length, min_periods=1, center=True).mean())\n",
    "\n",
    "    return(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "    \n",
    "# Apply sliding window\n",
    "\n",
    "# set window length to 20\n",
    "window_length = 20\n",
    "\n",
    "# apply sliding window (length 20) to the data from each experiment\n",
    "# obtain exp#_mean_window data for each experiment\n",
    "exp1_mean_window = apply_window(data_original[(data_original['Experiment']=='/sustain')], window_length)\n",
    "exp2_mean_window = apply_window(data_original[(data_original['Experiment']=='/variabl')], window_length)\n",
    "print('finish')\n",
    "\n",
    "# for each experiment\n",
    "for data,label in zip([exp1_mean_window, exp2_mean_window], ['sust', 'var']):\n",
    "\n",
    "    # make an empty plot_data dictionary key\n",
    "    plot_data[label] = {}\n",
    "\n",
    "    # average across all trials within each subject\n",
    "    group = data.reset_index().groupby(['UniqueID','Trial']).mean()\n",
    "\n",
    "    # melt/restructure the data\n",
    "    group_melt = pd.melt(group.reset_index(), id_vars=['UniqueID','Trial'], value_vars=['Category', 'Full','None','Nov_Un', 'Nov_Cued','Side'])\n",
    "\n",
    "    # assign data to dictionary key\n",
    "    plot_data[label] = group_melt\n",
    "\n",
    "    # plotting color key\n",
    "    palette = sb.color_palette(\"RdBu\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sb.color_palette(\"RdBu\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window - Familiarity Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window - Novel Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# set plot style to white\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "# for keys in plot_data (that is, for each experiment)\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ' Sliding Window - Novel Images Only')\n",
    "\n",
    "    # select the data from that key\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot data\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Nov_Un','Nov_Cued'])], # ci=None,\n",
    "                palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13]})\n",
    "    ax.set(ylim=(1.3, 2.3))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xlabel('Memory Trial')\n",
    "    plt.ylabel('Familiarity')\n",
    "\n",
    "    # ttest at each timepoint ######################\n",
    "    ttest_data = timepoint_ttest(data, ['Nov_Cued','Nov_Un'])\n",
    "\n",
    "    # add lines where pvalue is significant\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.41, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "            plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.41, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "        plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "        # plt.axvline(x, .1, .3, color='red')\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"novel_time_susty.pdf\")\n",
    "    plt.show()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Image Difference Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in ['sust','var']: # plot_data.keys():\n",
    "\n",
    "    print(key + ' Group : Sliding Window - Novel Images Only')\n",
    "\n",
    "    # exp = plot_data[key][label]\n",
    "\n",
    "    trial_avs = plot_data[key].groupby(['Trial','Attention Level','UniqueID'], as_index=False).mean()\n",
    "    trial_avs['Nov_Diffs'] = np.nan\n",
    "\n",
    "    for s in trial_avs['UniqueID'].unique():\n",
    "        for t in trial_avs['Trial'].unique():\n",
    "\n",
    "            first  = trial_avs[(trial_avs['Attention Level']=='Nov_Cued') \n",
    "                               & (trial_avs['Trial']==t)\n",
    "                              & (trial_avs['UniqueID']==s)]['value'].item()\n",
    "\n",
    "            second = trial_avs[(trial_avs['Attention Level']=='Nov_Un'  ) \n",
    "                               & (trial_avs['Trial']==t)\n",
    "                              & (trial_avs['UniqueID']==s)]['value'].item()\n",
    "\n",
    "            difference = first - second\n",
    "\n",
    "            trial_avs.loc[(trial_avs['Trial']==t) & (trial_avs['UniqueID']==s),'Nov_Diffs'] = first - second\n",
    "\n",
    "    ax = sb.lineplot(x='Trial', y='Nov_Diffs', data=trial_avs)\n",
    "    ax.set(ylim=(-.1, .4))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    sb.regplot(x=\"Trial\", y=\"Nov_Diffs\", data=trial_avs, scatter=False)\n",
    "\n",
    "    trial_av_grp = trial_avs.groupby(['Trial'], as_index=False).mean()\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(trial_avs['Trial'], trial_avs['Nov_Diffs'])\n",
    "\n",
    "    print('slope = ' + str(slope))\n",
    "    print('intercept = ' + str(intercept))\n",
    "    print('p_value = ' + str(p_value))\n",
    "    print()\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xlabel('Memory Trial')\n",
    "    plt.ylabel('Familiarity Difference')\n",
    "    plt.savefig(label+\"_novel_diff_susty.pdf\")\n",
    "\n",
    "    #print(exp)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncued Category images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(plot_data.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot data\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Side','None','Nov_Un'])], # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], 'Novel':'black'}) \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.2, 3.2))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "\n",
    "    # stats test\n",
    "    data = data[data['Attention Level'].isin(['Side','None','Nov_Un'])]\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Side','Nov_Un'])#, related=False)\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "\n",
    "        else:\n",
    "            plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "            plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "\n",
    "\n",
    "        # ttest at each timepoint #################\n",
    "        ttest_data = timepoint_ttest(data, ['Side','None'])\n",
    "\n",
    "        # lines w/ sig pval #######################\n",
    "        index = ttest_data[(ttest_data['Attention Level']=='Side') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "        index = set(index)\n",
    "\n",
    "        for x in ranges(index):\n",
    "            if x[0] == x[1]:\n",
    "                x_new_0 = x[0]-.1\n",
    "                x_new_1 = x[1]+.1\n",
    "\n",
    "                plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "                plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "\n",
    "            else:\n",
    "                plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "                plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "\n",
    "        # ttest at each timepoint #################\n",
    "        ttest_data = timepoint_ttest(data, ['Nov_Un','None'])#, related=False)\n",
    "\n",
    "        # lines w/ sig pval #######################\n",
    "        index = ttest_data[(ttest_data['Attention Level']=='Nov_Un') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "        index = set(index)\n",
    "\n",
    "        for x in ranges(index):\n",
    "\n",
    "            if x[0] == x[1]:\n",
    "                x_new_0 = x[0]-.1\n",
    "                x_new_1 = x[1]+.1\n",
    "\n",
    "                plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "                plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[13])\n",
    "\n",
    "            else:\n",
    "                plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "                plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[13])\n",
    "\n",
    "\n",
    "        plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "        plt.savefig(label+\"_uncued_categories.pdf\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window - Images in Cued Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Full', 'Nov_Cued', 'Category'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.2, 3.2))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','Nov_Cued'])#, related=False)    \n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Nov_Cued') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "\n",
    "    # ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','Full'])\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Category') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.52, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.5, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "        plt.axhline( y=1.52, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.5, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "\n",
    "\n",
    "    # ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Nov_Cued','Full'])\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Full') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.42, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.4, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[5])\n",
    "\n",
    "        plt.axhline( y=1.42, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.4, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[5])\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "    \n",
    "    plt.savefig(label+\"cued_categories_newest.pdf\")\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sliding window\n",
    "window_length = 20\n",
    "\n",
    "plot_data = {}\n",
    "    \n",
    "# Apply sliding window\n",
    "\n",
    "window_length = 20\n",
    "\n",
    "exp1_mean_window = apply_window(data_original[(data_original['Experiment']=='/sustain')], window_length)\n",
    "exp2_mean_window = apply_window(data_original[(data_original['Experiment']=='/variabl')], window_length)\n",
    "print('finish')\n",
    "\n",
    "# end up with two dictionaries (one for each exp) each containing two keys ( for groups 1 & 2) \n",
    "\n",
    "        \n",
    "for data,label in zip([exp1_mean_window, exp2_mean_window], ['sust', 'var']):\n",
    "\n",
    "    plot_data[label] = {}\n",
    "\n",
    "    #for key in data.keys():\n",
    "\n",
    "    # average across all trials within each subject\n",
    "    group = data.reset_index().groupby(['UniqueID','Trial']).mean()\n",
    "\n",
    "    # melt/restructure the data\n",
    "    group_melt = pd.melt(group.reset_index(), id_vars=['UniqueID','Trial'], value_vars=['Category', 'Full','None','Nov_Un', 'Nov_Cued','Side'])\n",
    "\n",
    "    # assign data to dictionary key\n",
    "    plot_data[label] = group_melt\n",
    "\n",
    "    # plotting color key\n",
    "    palette = sb.color_palette(\"RdBu\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images in Cued Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Full', 'Side'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.2, 3.2))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Full','Side'])#, related=False)\n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Side') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[0])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[19])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[0])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[19])\n",
    "\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"_cued_location.pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images in Uncued Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sb.set_style(\"white\")\n",
    "\n",
    "for key in plot_data.keys():\n",
    "    \n",
    "    print(key + ': Sliding Window - Novel Images Only')\n",
    "\n",
    "    data = plot_data[key]\n",
    "\n",
    "    # plot ####################################\n",
    "    ax = sb.lineplot(x='Trial',y='value', hue = 'Attention Level', \n",
    "                data = data[data['Attention Level'].isin(['Category', 'None'])], # 'Category', # ci=None,\n",
    "                    palette = {\"Full\": palette[0], \"Category\": palette[3], \"Nov_Cued\":palette[5], \n",
    "                            \"Side\": palette[19], \"None\": palette[16], \"Nov_Un\":palette[13], \"Novel\":\"black\"})\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.set(ylim=(1.2, 3.2))\n",
    "    ax.set(xlim=(0, 39))\n",
    "\n",
    "    #ttest at each timepoint #################\n",
    "    ttest_data = timepoint_ttest(data, ['Category','None'])#, related=False)    \n",
    "\n",
    "    # lines w/ sig pval #######################\n",
    "    index = ttest_data[(ttest_data['Attention Level']=='Category') & (ttest_data['timepoint_t_truth']==True)]['Trial'].tolist()\n",
    "    index = set(index)\n",
    "\n",
    "\n",
    "    for x in ranges(index):\n",
    "\n",
    "        if x[0] == x[1]:\n",
    "            x_new_0 = x[0]-.1\n",
    "            x_new_1 = x[1]+.1\n",
    "\n",
    "            plt.axhline( y=1.32, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[3])\n",
    "            plt.axhline( y=1.3, xmin=x_new_0*(1/39), xmax=x_new_1*(1/39), color=palette[16])\n",
    "\n",
    "        plt.axhline( y=1.32, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[3])\n",
    "        plt.axhline( y=1.3, xmin=x[0]*(1/39), xmax=x[1]*(1/39), color=palette[16])\n",
    "\n",
    "\n",
    "\n",
    "    # plot settings & save ####################\n",
    "    plt.grid(False)\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.xlabel('Attention Level',    fontsize = 20)\n",
    "    plt.ylabel('Familiarity Rating', fontsize = 20)\n",
    "\n",
    "    plt.xticks([0, 9, 19, 29, 39])\n",
    "\n",
    "    plt.savefig(label+\"_uncued_location.pdf\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
